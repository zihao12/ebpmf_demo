---
title: "nmf_sparse"
author: "zihao12"
date: "2019-10-30"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

Adapted from https://stephens999.github.io/misc/nmf_sparse.html
We hope to see if `ebpmf` can get some sparse results compared to MLE algorithms. 

```{r warning=F, message=F}
devtools::load_all("../ebpmf.alpha/")
devtools::load_all("../ebpm/")
library("fastTopics")
library("NNLM") 
library("ebpmf")
```

## Introduction

The goal is to do some simple simulations where the factors are sparse
and look at the sparsity of the solutions from regular (unpenalized) nmf.

We simulate data with 3 factors with a "block-like"" structure.
```{r}
set.seed(123)
n = 99
p = 300
k= 3
L = matrix(0, nrow=n, ncol=k)
F = matrix(0, nrow=p, ncol=k)
L[1:(n/3),1] = 1
L[((n/3)+1):(2*n/3),2] = 1
L[((2*n/3)+1):n,3] = 1
  
F[1:(p/3),1] = 1+10*runif(p/3)
F[((p/3)+1):(2*p/3),2] = 1+10*runif(p/3)
F[((2*p/3)+1):p,3] = 1+10*runif(p/3)
lambda = L %*% t(F)
X = matrix(rpois(n=length(lambda),lambda),nrow=n)
image(X)
```

Now run the methods, and compute the Poisson log-likelihoods.
```{r warning=F, message=F}
fit_lee = NNLM::nnmf(A = X, k = 3, loss = "mkl", method = "lee", max.iter = 10000)
## scd
fit_scd = NNLM::nnmf(A = X, k = 3, loss = "mkl", method = "scd", max.iter = 10000)
k=3
fit0 <- list(F = matrix(runif(p*k),p,k),
             L = matrix(runif(n*k),n,k))
fit_sqp = altsqp(X,fit0,numiter = 20)

fit_ebpmf_pg = ebpmf_point_gamma(X, K = k, maxiter.out = 100)

sum(dpois(X, fit_sqp$L %*% t(fit_sqp$F),log=TRUE))
sum(dpois(X, fit_lee$W %*% fit_lee$H,log=TRUE))
sum(dpois(X, fit_scd$W %*% fit_scd$H,log=TRUE))
sum(dpois(X, fit_ebpmf_pg$qg$qls_mean %*% t(fit_ebpmf_pg$qg$qfs_mean),log=TRUE))
sum(dpois(X,lambda ,log=TRUE))

```

So all MLE algorithms find the same solution. `ebpmf_pg` also exceeds oracle.

Let's look at a factor/loading: the results are highly sparse.
```{r}
for(d in 1:k){
  plot(fit_sqp$L[,d],main=sprintf("estimated loadings %d", d))
}

for(d in 1:k){
  plot(fit_ebpmf_pg$qg$qls_mean[,d],main=sprintf("estimated loadings %d", d))

}
```


## Add a dense fourth factor

Now I add a fourth factor that is dense.
Note that we can make the problem much harder
by making the 4th (dense) factor have larger PVE (increase `mfac` in the code).
That may be useful for comparing methods on a harder problem...
```{r}
set.seed(123)
n = 99
p = 300
k= 4
mfac = 2 # controls PVE of dense factor
L = matrix(0, nrow=n, ncol=k)
F = matrix(0, nrow=p, ncol=k)
L[1:(n/3),1] = 1
L[((n/3)+1):(2*n/3),2] = 1
L[((2*n/3)+1):n,3] = 1
L[,4] = 1+mfac*runif(n)
F[1:(p/3),1] = 1+10*runif(p/3)
F[((p/3)+1):(2*p/3),2] = 1+10*runif(p/3)
F[((2*p/3)+1):p,3] = 1+10*runif(p/3)
F[,4]= 1+mfac*runif(p)
lambda = L %*% t(F)
X = matrix(rpois(n=length(lambda),lambda),nrow=n)
image(X)
```



Run the methods. I also run altsqp initialized from the truth to check if it affects the result.
```{r warning=F, message=F}
k = 4
fit_lee = NNLM::nnmf(A = X, k = k, loss = "mkl", method = "lee", max.iter = 10000)
## scd
fit_scd = NNLM::nnmf(A = X, k = k, loss = "mkl", method = "scd", max.iter = 10000)
fit0 <- list(F = matrix(runif(p*k),p,k),
             L = matrix(runif(n*k),n,k))
fit_sqp = altsqp(X,fit0,numiter = 50,verbose = FALSE)
# also fit initialized from truth
fit_true <- list(F = F,L = L)
fit_sqp2 = altsqp(X,fit_true,numiter = 20)

fit_ebpmf_pg = ebpmf::ebpmf_point_gamma(X, K = k, maxiter.out = 100)

## also initialize from truth
qg_from_true = initialize_qg_from_LF(L, F)
fit_ebpmf_pg2 = ebpmf::ebpmf_point_gamma(X = X, K = k, qg = qg_from_true,maxiter.out = 100)

sum(dpois(X, fit_lee$W %*% fit_lee$H,log=TRUE))
sum(dpois(X, fit_scd$W %*% fit_scd$H,log=TRUE))
sum(dpois(X, fit_sqp$L %*% t(fit_sqp$F),log=TRUE))
sum(dpois(X, fit_sqp2$L %*% t(fit_sqp2$F),log=TRUE))
sum(dpois(X, fit_ebpmf_pg$qg$qls_mean %*% t(fit_ebpmf_pg$qg$qfs_mean),log=TRUE))
sum(dpois(X, fit_ebpmf_pg2$qg$qls_mean %*% t(fit_ebpmf_pg2$qg$qfs_mean),log=TRUE))

sum(dpois(X, L %*% t(F),log=TRUE))
```
All the methods find a solution
whose loglikelihood exceeds the oracle.

Look at the loadings, we see that the sparse loadings are a bit "messy".
```{r}
## scd
for(i in 1:k){
  plot(fit_sqp2$L[,i],main=paste0("estimated loadings ",i))
}

## sqp initialize from truth
for(i in 1:k){
  plot(fit_scd$W[,i],main=paste0("estimated loadings ",i))
}

## ebpmf_pg 
for(d in 1:k){
  plot(fit_ebpmf_pg$qg$qls_mean[,d],main=sprintf("estimated loadings %d", d))

}

## ebpmf_pg iniialize from truth
for(d in 1:k){
  plot(fit_ebpmf_pg2$qg$qls_mean[,d],main=sprintf("estimated loadings %d", d))

}
```

Well initialization  is very important for the sparsity pattern  of `ebpmf`!!


Let's look  at the priors for L from the two `ebpmf_pg` fits. 
```{r}
fit_ebpmf_pg$qg$gls

fit_ebpmf_pg2$qg$gls
```



















