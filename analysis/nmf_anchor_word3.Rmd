---
title: "NMF experiments 3"
author: "zihao12"
date: "2019-12-17"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction
I simulate data under the anchor words assumption, using multinomial model:\

Let $A \in R^{p \times k}$ be $k$ topics (each column sums to one, nonnegative). We require that for each topic, there is at least one "anchor word" $i_k$ so that $A_{i_k, j} > 0, A_{i \neq i_k, j} = 0$. I relax the strictly zero to some small  value compared to. \

Then $Prob = A W$, $X_{Ij} \sim Multinom(N_j, Prob_{Ij})$ (note $X \in R^{p \times n}$). 

## Data simulation. 
```{r message=FALSE, warning=FALSE}
rm(list = ls())
library(NNLM)
library(ebpm)
devtools::load_all("../ebpmf.alpha")
source("code/misc.R")
set.seed(123)
n = 100
p = 500
k = 5
anchor_word_per_topic = 5
sep_val = 1
M = round(p/3)

A = matrix(runif(p*k), ncol = k)
W = matrix(replicate(n*k, 0), nrow = k)
X = matrix(replicate(n*p, 0), nrow = p)

## get set of anchor words (id)
##  each topic has only 10 anchor word
S = sort(sample(x = 1:p, size = anchor_word_per_topic*k, replace = TRUE))
start_id = seq(1, anchor_word_per_topic*(k-1) + 1, length.out = k)

## generate A
for(d in 1:k){
  if(d < k){an_words = S[start_id[d]:(start_id[d+1]-1)]}
  else{an_words = S[start_id[d]:length(S)]}
  A[an_words, d] = sort(2 * k * sep_val * runif(n = anchor_word_per_topic, min = 0.4, max = 0.6))
}
A = t(t(A)/colSums(A))

## generate W
## each document has at most 3 topics (roughly)
for(i in 1:n){
  cardin = sample(x = 1:floor(k/3), size = 1)
  top_supp = sample(x = 1:k, size = cardin, replace = TRUE)
  W[top_supp,i] = runif(cardin)
  W[, i] = W[,i]/sum(W[,i])
}

prob_m = A %*% W

for(i in 1:n){
  n_word = rpois(n = 1, lambda = M)
  X[,i] = rmultinom(n = 1, size = n_word, prob = prob_m[,i])
}

print(sprintf("percentage of 0s: %f", sum(X == 0)/(n*p)))

## save simulation for possible comparison with `anchorwords`
write.table(A, "data/nmf_anchor_word3_A.csv", row.names = FALSE, col.names = FALSE)
write.table(W, "data/nmf_anchor_word3_W.csv", row.names = FALSE, col.names = FALSE)
write.table(X, "data/nmf_anchor_word3_X.csv", row.names = FALSE, col.names = FALSE)
```


## Fit 
```{r cache=TRUE, message=FALSE, warning=FALSE}
## fit with MLE_EM
fit_mle_em = NNLM::nnmf(A = t(X), k = k, loss = "mkl", method = "scd", max.iter = 10000)
lf_mlf_em = poisson2multinom(F = t(fit_mle_em$H), L = fit_mle_em$W)
A_em = lf_mlf_em$F
W_em = t(lf_mlf_em$L)

```


Let's see if we can choose topics by anchor words

```{r}
find_closest <- function(v, V){
  min_dist = Inf
  cand = -1
  for(i in 1:ncol(V)){
    curr_dist = sum((v - V[,i])^2)
    if(curr_dist < min_dist){
      min_dist = curr_dist
      cand = i
    }
  }
  return(cand)
}



anchor_set = apply(A, 2, which.max)

anchor_set_em = apply(A_em, 2, which.max)
aligned_em = replicate(k, -1)
for(d in 1:k){
  if(d < k){anchor_words = S[start_id[d]:(start_id[d+1]-1)]}
  else{anchor_words = S[start_id[d]:length(S)]}
  
  ## only look at those anchor words and look at which topic is closest
  curr_id = find_closest(A[anchor_words,d], A_em[anchor_words,])
  aligned_em[d] = curr_id
}
## aligned topics 
aligned_em
```


fit with EBPMF
```{r cache=TRUE, message=FALSE, warning=FALSE}
#library(ebpmf.alpha)
#eps = .Machine$double.xmin
eps = 0
qg0 = ebpmf.alpha::initialize_qg_from_LF(L0 = fit_mle_em$W + eps, F0 = t(fit_mle_em$H + eps))
fit_ebpmf_two_gamma = ebpmf.alpha::ebpmf_two_gamma(X = t(X), K = k, maxiter.out = 200, verbose = TRUE)
```


```{r}
lf_ebpmf = poisson2multinom(F = fit_ebpmf_two_gamma$qg$qfs_mean, L = fit_ebpmf_two_gamma$qg$qls_mean)
A_ebpmf = lf_ebpmf$F
W_ebpmf = t(lf_ebpmf$L)

anchor_set_ebpmf = apply(A_ebpmf, 2, which.max)
aligned_ebpmf = replicate(k, -1)
for(d in 1:k){
  if(d < k){anchor_words = S[start_id[d]:(start_id[d+1]-1)]}
  else{anchor_words = S[start_id[d]:length(S)]}
  
  ## only look at those anchor words and look at which topic is closest
  curr_id = find_closest(A[anchor_words,d], A_ebpmf[anchor_words,])
  aligned_ebpmf[d] = curr_id
}
## aligned topics 
aligned_ebpmf
```


```{r}
par(mfrow=c(2,3))
for(d in 1:k){
  plot(A[,d],main = sprintf("true topic %d", d))
  plot(A_ebpmf[,aligned_ebpmf[d]], main = sprintf("ebpmf topic %d", d))
  plot(A_em[,aligned_em[d]], main = sprintf("mle topic %d", d))
}
```



Compare likelihood $p(X|A, W)$.
```{r}
Lam_true = A %*% W %*% diag(colSums(X))
Lam_em = A_em %*% W_em %*% diag(colSums(X))
Lam_ebpmf = A_ebpmf %*% W_ebpmf %*% diag(colSums(X))

## likelihood for truth
sum(dpois(x = X, lambda = Lam_true,log = TRUE))

## likelihood for em result
sum(dpois(x = X, lambda = Lam_em,log = TRUE))

## likelihood for ebpmf result
sum(dpois(x = X, lambda = Lam_ebpmf,log = TRUE))
```



Compare ELBO

For truth and MLE result, I initialize q,g with them and run 1 iteration. 
```{r message=FALSE, warning=FALSE}
## ELBOP FOR EBPMF
fit_ebpmf_two_gamma$ELBO[length(fit_ebpmf_two_gamma$ELBO)]

## ELBO for TRUE
qg_true = ebpmf.alpha::initialize_qg_from_LF(F0 = A, L0 = t(W %*% diag(colSums(X))))
fit_tmp = ebpmf.alpha::ebpmf_two_gamma(X = t(X), K = k, qg = qg_true, maxiter.out = 1)
fit_tmp$ELBO


## ELBO FOR MLE
qg_mle = ebpmf.alpha::initialize_qg_from_LF(F0 = t(fit_mle_em$H), L0 = fit_mle_em$W)
fit_mle = ebpmf.alpha::ebpmf_two_gamma(X = t(X), K = k, qg = qg_mle, maxiter.out = 1)
fit_mle$ELBO
```



```{r}
plot(fit_ebpmf_two_gamma$ELBO)

fit_ebpmf_two_gamma$qg$gfs

fit_ebpmf_two_gamma$qg$gls
```

## Conclusion
* `ebpmf` with two gammas has some optimization issues: ELBO sometimes jump to a very large number; sometimes get ELBO gets NaN (in iteration 448 in this example). Need to figure it out.

* ELBO: Truth > ebpmf >  MLE

* `ebpmf_two_gamma` seems to be small advantages over `mle` result.  











