---
title: "demo_sparse_ebpmf_two_gamma"
author: "zihao12"
date: "2020-01-21"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction
The goal is to simulate data with sparse factors and loadings, and see which method can recover them. I compare our method `ebpmf_two_gamma` with MLE (using lee's multiplicative update) for Poisson Matrix Factorization. 
```{r warning=F, message=F}
rm(list = ls())
library("NNLM")
library("ebpm")
library("ebpmf")
source("code/misc.R")
```

## Simulate data and fit 
Let $\Lambda = \sum_{k = 1}^4 l_{ik} f_{jk}$ be the underlying mean. The first 3 loadings & factors have a "block-like" structure. The 4th loading and factor are noise. \

```{r cache=TRUE, autodep=TRUE, message=FALSE, warning=FALSE}
set.seed(123)
n = 99
p = 300
k= 4
mfac = 2.5 # controls PVE of dense factor
L = matrix(0, nrow=n, ncol=k)
F = matrix(0, nrow=p, ncol=k)
L[1:(n/3),1] = 1
L[((n/3)+1):(2*n/3),2] = 1
L[((2*n/3)+1):n,3] = 1
L[,4] = 1+mfac*runif(n)

F[1:(p/3),1] = 1+10*runif(p/3)
F[((p/3)+1):(2*p/3),2] = 1+10*runif(p/3)
F[((2*p/3)+1):p,3] = 1+10*runif(p/3)
F[,4]= 1+mfac*runif(p)
lambda = L %*% t(F)
X = matrix(rpois(n=length(lambda),lambda),nrow=n)

```

I fit with `ebpmf_two_gamma` and MLE. Assume the true number of topics is known. 

MLE uses EM algorithm so I use 10000 iterations so that it is close to convergence. 

For `ebpmf_two_gamma` I find 500 iterations are good enough. 
```{r cache=TRUE, autodep=TRUE, message=FALSE, warning=FALSE}
k = 4
fit_lee = NNLM::nnmf(A = X, k = k, loss = "mkl", method = "lee", max.iter = 10000, verbose = FALSE)
fit_ebpmf_tg = ebpmf.alpha::ebpmf_two_gamma(X, K = k, maxiter.out = 500, verbose = FALSE)
```


## what does the data look like
I show the matrix X
```{r}
image(X)
## show scaled L, F
## I transfrom the L, F from the Poisson model to the multinomial model
# lf_truth = poisson2multinom(F = F, L = L)
# par(mfrow = c(2,2))
# for(i in 1:k){
#   plot(lf_truth$L[,i],main=paste0("true loading (scaled)",i), ylab = "loading")
# }
# par(mfrow = c(2,2))
# for(i in 1:k){
#   plot(lf_truth$F[,i],main=paste0("true factor (scaled)",i), ylab = "factor")
# }
```


## Compare the loadings:
```{r}
## show true L
par(mfrow = c(2,2))
for(i in 1:k){
  plot(L[,i],main=paste0("true loading ",i), ylab = "loading")
}

## lee from truth
par(mfrow = c(2,2))
for(i in 1:k){
  plot(fit_lee$W[,i],main=paste0("mle_lee: loadings ",i), ylab = "loading")
}

## ebpmf_tg
par(mfrow = c(2,2))
for(d in 1:k){
  plot(fit_ebpmf_tg$qg$qls_mean[,d],main=sprintf("ebpmf_two_gamma: loadings %d", d), ylab = "loading")
}
```
* MLE solution does not get sparse loadings, though the basic structure is right. 

* two-gamma gets the sparse loadings!

## Compare the factors:
```{r}
## show true F
par(mfrow = c(2,2))
for(i in 1:k){
  plot(F[,i],main=paste0("true factor ",i), ylab = "factor")
}

## lee from truth
par(mfrow = c(2,2))
for(i in 1:k){
  plot(fit_lee$H[i,],main=paste0("mle_lee: factors ",i), ylab = "factor")
}

## ebpmf_tg
par(mfrow = c(2,2))
for(d in 1:k){
  plot(fit_ebpmf_tg$qg$qfs_mean[,d],main=sprintf("ebpmf_two_gamma: factors %d", d), ylab = "factor")
}
```

* Both methods get the basic structure, but fails to get the sparse solutions.

* Factors are harder to recover for the `ebpmf_two_gamma` in this example, because the randomness in the signal makes the `ebpm` subproblem harder to solve (difficult to identify clusters).  


