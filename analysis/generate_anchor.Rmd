---
title: "Generate data from anchor word model"
author: "zihao12"
date: "2019-12-11"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction
Because of the identifiability issue in previous experiments, I simulate data under the anchor words assumption:\

Let $A \in R^{p \times k}$ be $k$ topics (each column sums to one, nonnegative). We require that for each topic, there is at least one "anchor word" $i_k$ so that $A_{i_k, j} > 0, A_{i \neq i_k, j} = 0$. I relax the strictly zero to some small  value compared to. \

Then $Prob = A W$, $X_{Ij} \sim Multinom(N_j, Prob_{Ij})$ (note $X \in R^{p \times n}$). 

## Data simulation. 
```{r}
set.seed(123)
n = 100
p = 500
k = 10
sep_val = 1 ## the bigger value, the more "separable"
M = 2*p ## (mean) number of words per document

A = matrix(runif(p*k), ncol = k)
W = matrix(replicate(n*k, 0), nrow = k)
X = matrix(replicate(n*p, 0), nrow = p)

## get set of anchor words (id)
## for simplicity, each topic has only one anchor word
S = sample(x = 1:p, size = k, replace = TRUE)

## generate A
for(d in 1:k){
  A[S[d], d] = k * sep_val
}
A = t(t(A)/colSums(A))

## generate W
for(i in 1:n){
  cardin = sample(x = 1:floor(k/3), size = 1)
  top_supp = sample(x = 1:k, size = cardin, replace = TRUE)
  W[top_supp,i] = runif(cardin)
  W[, i] = W[,i]/sum(W[,i])
}

prob_m = A %*% W

for(i in 1:n){
  n_word = rpois(n = 1, lambda = M)
  X[,i] = rmultinom(n = 1, size = n_word, prob = prob_m[,i])
}

print(sprintf("percentage of 0s: %f", sum(X == 0)/(n*p)))
```


## Fit with `LDA`
```{r}
library(topicmodels)
fit_lda = LDA(x = t(X), k = k, method = "Gibbs")
A_lda = t(exp(fit_lda@beta))
W_lda = t(fit_lda@gamma)
```

## Compare topics
```{r}
image(A)
image(A_lda)
```



Let's see if we can choose topics by anchor words
```{r}
anchor_set = apply(A, 2, which.max)
anchor_set_lda = apply(A_lda, 2, which.max)

aligned_ind = replicate(k, -1)
for(d in 1:k){
  anchor_word = anchor_set[d]
  if(anchor_word %in% anchor_set_lda){
    curr_id = which(anchor_set_lda == anchor_word)
  }else{curr_id = -1}
  aligned_ind[d] = curr_id
}
aligned_ind
```
All topics are aligned by anchor word! 


```{r}
par(mfrow=c(2,2))
for(d in 1:k){
  plot(A[,d],main = sprintf("topic %d", d))
  plot(A_lda[,aligned_ind[d]], main = sprintf("topic %d", d))
}
```


Compare likelihood $p(X|A, W)$.
```{r}
Lam_true = A %*% W %*% diag(colSums(X))
Lam_lda = A_lda %*% W_lda %*% diag(colSums(X))

## likelihood for truth
sum(dpois(x = X, lambda = Lam_true,log = TRUE))

## likelihood for LDA result
sum(dpois(x = X, lambda = Lam_lda,log = TRUE))
```


## Conclusion
* LDA is able to find topics correctly in this simple example, but the estimate has some wrong signals. Its likelihood is also worse than truth. 

* The ability to recover true $A$ depends on the number of words per document. I tried using $p$ and it fails to identify one topic. Not surprising. 

## To do
* Make a set  of anchor words for each topic ... more noise ...

* Run MLE (EM or second-order methods). 

* Run `anchor word` type methods

* See how `ebpmf` performs. 
















